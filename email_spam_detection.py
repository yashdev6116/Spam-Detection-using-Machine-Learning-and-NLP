# -*- coding: utf-8 -*-
"""Email_Spam_Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tW13YtSjL-q6Gd-SR_5Kmah-1WuOPovC
"""

from google.colab import files
upload=files.upload()

import pandas as pd
import numpy as np

data=pd.read_csv("/content/spam.csv")

data.head()

data.isnull().sum()

#data['Category'] = data['Category'].map({'spam':1,'ham':0})
#data.head()

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
import re

def preprocess_text(text):
    text = re.sub(r'[^\w\s]', '', text) # remove punctuation
    text = text.lower()
    tokens = nltk.word_tokenize(text) # Tokenization
    stop_words = set(stopwords.words('english'))
    tokens = [w for w in tokens if not w in stop_words] # Remove stop words
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(w) for w in tokens] # Lemmatization
    return " ".join(tokens)

data['Message'] = data['Message'].apply(preprocess_text)

print(data[['Message']].head())

data.head()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Encode labels
data['Category'] = data['Category'].map({'ham': 0, 'spam': 1})

data.head()

# Split data
X_train, X_test, y_train, y_test = train_test_split(data['Message'], data['Category'], test_size=0.2, random_state=42)

# Vectorize text data
vectorizer = TfidfVectorizer()
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Train the model
model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import joblib

# Save the model and vectorizer
joblib.dump(model, 'spam_detection_model.pkl')
joblib.dump(vectorizer, 'vectorizer.pkl')

# Loading the model and vectorizer for prediction
model_loaded = joblib.load('spam_detection_model.pkl')
vectorizer_loaded = joblib.load('vectorizer.pkl')

# Function to predict if a message is spam or not
def predict_message(message):
    processed_message = preprocess_text(message)
    message_tfidf = vectorizer_loaded.transform([processed_message])
    prediction = model_loaded.predict(message_tfidf)
    return "spam" if prediction[0] == 1 else "ham"

# Test prediction
new_message =input("Enter the Message: ")
prediction = predict_message(new_message)
print(f"The message is: {prediction}")